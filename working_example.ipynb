{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46fe0f17",
   "metadata": {},
   "source": [
    "__Loading modules and objects required__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2134b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from text_utils import (\n",
    "    TextDataset,\n",
    "    TextTokenizer, \n",
    "    TextProcessor\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import (\n",
    "    META_PATH, \n",
    "    SEED, \n",
    "    TEST_SIZE,\n",
    "    load_pickle,\n",
    "    dump_pickle,\n",
    "    set_seed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6a0522",
   "metadata": {},
   "source": [
    "__Initializing text processor and obtaining IMDB text corpus__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "729976ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62e8dc20af447aea75ec189d9c2d263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = TextProcessor(META_PATH)\n",
    "corpus, labels = processor.get_corpus()\n",
    "train_corpus, test_corpus, y_train, y_test = train_test_split(corpus,\n",
    "                                                              labels,\n",
    "                                                              test_size=TEST_SIZE,\n",
    "                                                              random_state=SEED)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdd0013",
   "metadata": {},
   "source": [
    "__Initializing text tokenizer and tokenizing text__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1e1c7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33c3ee4584645bca8fb7148a70dddb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d976581377a408593c2467fade65e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = TextTokenizer(pad_method=\"center\")\n",
    "train_tokenized = tokenizer.fit_transform(train_corpus)\n",
    "test_tokenized = tokenizer.transform(test_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd8cb5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_pickle(test_corpus, \"test_corpus.pkl\")\n",
    "dump_pickle(test_tokenized, \"test_tokenized.pkl\")\n",
    "dump_pickle(tokenizer, \"tokenizer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401dfc36",
   "metadata": {},
   "source": [
    "__Printing several examples of tokenizing and detokenizing text__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26155fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = load_pickle(\"test_corpus.pkl\")\n",
    "test_tokenized = load_pickle(\"test_tokenized.pkl\")\n",
    "tokenizer = load_pickle(\"tokenizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a828950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what a refreshing change from the pg movies that have teen girls jumping in and out of bed young high school boys counting how many girls they can hook up with kids drinking doing drugs etc . etc . etc . carl hiaasen has written so many books that are enjoyable but hardly classic literature . but he has finally written something that middle school kids want to read . and this movie sends a message to kids that maybe they can make a difference that maybe their voices can be heard . filmed in south florida the scenery is beautiful and natural and real . who cares if its predictable and a little corny . so was free willy and look how well that did . this is a good family movie . . . . . . . . . . a rare breed .\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 93, 45, 4145, 1868, 329, 23, 3610, 466, 20, 51, 6602, 195, 9095, 40, 15, 179, 47, 2549, 88, 1878, 818, 1631, 23437, 232, 28, 195, 137, 523, 17039, 174, 123, 1501, 3919, 1582, 1335, 1358, 11, 1358, 11, 1358, 11, 2329, 3, 225, 3185, 213, 28, 5569, 20, 27, 1926, 125, 2130, 770, 16117, 11, 125, 422, 225, 2639, 3185, 255, 20, 1644, 818, 1501, 303, 140, 22, 11, 15, 6, 307, 675, 45, 2147, 140, 1501, 20, 472, 137, 523, 57, 45, 6818, 20, 472, 156, 3147, 523, 204, 956, 11, 366, 40, 2470, 6926, 23, 958, 62, 80, 15, 3484, 15, 296, 11, 450, 497, 101, 12, 2355, 15, 45, 191, 8995, 11, 213, 44, 2957, 3, 15, 369, 232, 387, 20, 128, 11, 6, 62, 45, 317, 1779, 307, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 45, 1924, 27674, 11, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "what a refreshing change from the pg movies that have teen girls jumping in and out of bed young high school boys counting how many girls they can hook up with kids drinking doing drugs etc . etc . etc . carl unk_tok has written so many books that are enjoyable but hardly classic literature . but he has finally written something that middle school kids want to read . and this movie sends a message to kids that maybe they can make a difference that maybe their voices can be heard . filmed in south florida the scenery is beautiful and natural and real . who cares if its predictable and a little corny . so was free unk_tok and look how well that did . this is a good family movie . . . . . . . . . . a rare breed .\n",
      "\n",
      "\n",
      "this is without doubt rajnikanths worst movies ever . the first part is held in place with solid comedy from goundamani but it progressively gets worse and worse and completely illogical . our hero also takes a dig at saints with the same name baba through a corny and utterly lame oneliner . the first half has rajni uttering his usual array of oneliners and style and in the second half becomes a quasi saint after a beggar takes him through a interdimensional portal to the himalayas where babaji not the famous saints he took a dig at earlier gives him special powers for no apparent reason other than karma . this is really starting to get interesting now isnt it the rest of the movie is about him wasting his magic boons and powers and fighting off politicians and related black magic . the usual predictable crap with hilarious implementation . oh and the black magic never worked on our hero because he just happened to have a param vir . . . er . . . . shakti chakra with him . the bad guys and the usual politician villains are clichd overworked and in the end completely insignificant to the plot which itself doesnt go anywhere . but despite all the flaws it was fun to kill time with and yell baba related oneliners during public events . its also fun to watch others curse about this movie . ar rehman is said to have composed the tracks for his movie through the cell phone . thats how important he considered it . rajni is very popular in japan and he has included two characters one of them is called keiko . . . why not samsung of japanese origin in this movie just for the sake of it . but the way they are portrayed dressed and treated is absolutely pathetic . the japanese may stop watching rajni movies after seeing that . this movie was probably promotional material for rajni entering politics but the results of the movie itself would have killed off any of his political dreams . fun if you turn your brain off though .\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 6, 62, 73, 2712, 3, 1735, 466, 639, 11, 23, 519, 167, 62, 4471, 40, 1215, 123, 2286, 67, 329, 3, 125, 43, 3, 264, 1056, 15, 1056, 15, 876, 2412, 11, 682, 683, 436, 315, 45, 5102, 155, 15504, 123, 23, 564, 654, 3, 251, 45, 8995, 15, 9618, 1279, 3, 11, 23, 519, 1386, 225, 3, 3, 433, 1478, 5031, 47, 6149, 15, 2179, 15, 40, 23, 1907, 1386, 2039, 45, 3, 19044, 283, 45, 3, 315, 489, 251, 45, 3, 3, 140, 23, 3, 738, 3, 83, 23, 1332, 15504, 422, 4475, 45, 5102, 155, 3935, 635, 489, 1594, 1200, 18, 347, 6965, 300, 574, 517, 3, 11, 6, 62, 302, 5697, 140, 146, 1485, 575, 446, 43, 23, 508, 47, 23, 307, 62, 187, 489, 6527, 433, 5986, 3, 15, 1200, 15, 1577, 196, 7260, 15, 3536, 66, 5986, 11, 23, 1478, 2355, 3193, 123, 136, 3, 11, 350, 15, 23, 66, 5986, 484, 1365, 234, 682, 683, 60, 422, 278, 1173, 140, 51, 45, 3, 3, 11, 11, 11, 9060, 11, 11, 11, 11, 3, 3, 123, 489, 11, 23, 361, 145, 15, 23, 1478, 415, 787, 27, 531, 3, 15, 40, 23, 527, 876, 15210, 140, 23, 503, 53, 506, 56, 91, 2382, 11, 125, 509, 96, 23, 55, 43, 44, 959, 140, 1565, 48, 123, 15, 15483, 3, 3536, 6149, 583, 2435, 1526, 11, 12, 436, 959, 140, 304, 295, 5104, 187, 6, 307, 11, 3, 3, 62, 1579, 140, 51, 9971, 23, 7323, 18, 433, 307, 251, 23, 2306, 2592, 11, 349, 232, 1821, 422, 118, 43, 11, 3, 62, 467, 1500, 40, 7265, 15, 422, 225, 4772, 9, 431, 222, 47, 61, 62, 2126, 3, 11, 11, 11, 231, 83, 3, 47, 2652, 7570, 40, 6, 307, 278, 18, 23, 3030, 47, 43, 11, 125, 23, 70, 137, 27, 1732, 5251, 15, 428, 62, 1879, 71, 11, 23, 2652, 138, 2245, 311, 3, 466, 283, 1264, 20, 11, 6, 307, 44, 274, 3, 881, 18, 3, 5242, 6834, 125, 23, 6751, 47, 23, 307, 506, 301, 51, 289, 196, 331, 47, 433, 5422, 1183, 11, 959, 101, 36, 1437, 500, 3921, 196, 536, 11, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "this is without doubt unk_tok worst movies ever . the first part is held in place with solid comedy from unk_tok but it unk_tok gets worse and worse and completely illogical . our hero also takes a dig at saints with the same name unk_tok through a corny and utterly lame unk_tok . the first half has unk_tok unk_tok his usual array of oneliners and style and in the second half becomes a unk_tok saint after a unk_tok takes him through a unk_tok unk_tok to the unk_tok where unk_tok not the famous saints he took a dig at earlier gives him special powers for no apparent reason other than unk_tok . this is really starting to get interesting now isnt it the rest of the movie is about him wasting his magic unk_tok and powers and fighting off politicians and related black magic . the usual predictable crap with hilarious unk_tok . oh and the black magic never worked on our hero because he just happened to have a unk_tok unk_tok . . . er . . . . unk_tok unk_tok with him . the bad guys and the usual politician villains are clichd unk_tok and in the end completely insignificant to the plot which itself doesnt go anywhere . but despite all the flaws it was fun to kill time with and yell unk_tok related oneliners during public events . its also fun to watch others curse about this movie . unk_tok unk_tok is said to have composed the tracks for his movie through the cell phone . thats how important he considered it . unk_tok is very popular in japan and he has included two characters one of them is called unk_tok . . . why not unk_tok of japanese origin in this movie just for the sake of it . but the way they are portrayed dressed and treated is absolutely pathetic . the japanese may stop watching unk_tok movies after seeing that . this movie was probably unk_tok material for unk_tok entering politics but the results of the movie itself would have killed off any of his political dreams . fun if you turn your brain off though .\n",
      "\n",
      "\n",
      "this has got to be the best movie ive ever seen . combine breathtaking cinematography with stunning acting and a gripping plot and you have a masterpiece . dog bite dog had me gripping the edge of my seat during some scenes recoiling in horror during others and left me drowning in my own tears after the tragic ending . the film left a deep impression on me . its shockingly violent scenes contrasted sharply with the poignant and tender love scenes . the film is undeserving of its cat iii nudity rating there are no nude scenes whatsoever and the love scenes do not even involve kissing or making out . the message which this film presented to me all human beings no matter how violent or cruel they may seem have a tender side . edison chen does a superb job playing the part of the murderous pang . i rate this film 1010 . its a mustwatch .\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 6, 225, 1311, 140, 204, 23, 594, 307, 638, 639, 640, 11, 10575, 3358, 613, 123, 607, 483, 15, 45, 4209, 503, 15, 36, 51, 45, 629, 11, 3205, 11818, 3205, 310, 124, 4209, 23, 499, 47, 120, 501, 583, 150, 345, 3, 40, 1540, 583, 295, 15, 184, 124, 1160, 40, 120, 2072, 3145, 283, 23, 1542, 291, 11, 23, 7, 184, 45, 3306, 2828, 234, 124, 11, 12, 5588, 2203, 345, 3, 3, 123, 23, 13610, 15, 12048, 909, 345, 11, 23, 7, 62, 3, 47, 12, 1529, 11407, 3146, 3859, 26, 27, 347, 7558, 345, 2683, 15, 23, 909, 345, 337, 83, 39, 15128, 4982, 288, 720, 179, 11, 23, 2147, 53, 6, 7, 2743, 140, 124, 96, 863, 2347, 347, 3144, 232, 2203, 288, 2993, 137, 138, 139, 51, 45, 12048, 1605, 11, 11474, 3, 481, 45, 1895, 482, 1286, 23, 167, 47, 23, 15382, 3, 11, 4, 3068, 6, 7, 11162, 11, 12, 45, 3, 11, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "this has got to be the best movie ive ever seen . combine breathtaking cinematography with stunning acting and a gripping plot and you have a masterpiece . dog bite dog had me gripping the edge of my seat during some scenes unk_tok in horror during others and left me drowning in my own tears after the tragic ending . the film left a deep impression on me . its shockingly violent scenes unk_tok unk_tok with the poignant and tender love scenes . the film is unk_tok of its cat iii nudity rating there are no nude scenes whatsoever and the love scenes do not even involve kissing or making out . the message which this film presented to me all human beings no matter how violent or cruel they may seem have a tender side . edison unk_tok does a superb job playing the part of the murderous unk_tok . i rate this film 1010 . its a unk_tok .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent_orig, sent_tok in zip(test_corpus[:3], test_tokenized[:3]):\n",
    "    print(\" \".join(sent_orig))\n",
    "    print(sent_tok)\n",
    "    print(\" \".join(tokenizer.get_text_from_vec(sent_tok)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f375b60d",
   "metadata": {},
   "source": [
    "__Construct CNN__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34cfde3",
   "metadata": {},
   "source": [
    "STEPS\n",
    "\n",
    "(0) dataloader\n",
    "\n",
    "(i) backbone\n",
    "\n",
    "(ii) train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e27c0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/quantized_nn/text_utils.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.meta[\"class\"] = self.meta[\"class\"].map(cls_map)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4baad195b7324b479a982017d298e974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0366de17afc849f295ccbe2cb332adf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6658325fb5a543e9aa9cc0f6a5e3dcaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d88b1337fee461ca7ff4b7c320686d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad82691ea1184c35a09ef13812593325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57bdd667a15241ad8d1e1c50a163629b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c769487ea247679b4938be134bb914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b440e160a642c2a73668609c1c677a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d071b98a94b4d3d9505227bb8f3e946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d776045aaa5498dbf42bdaafb8fc605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159318f184564dffa67a60fb373ad414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506e01fca1484244a576de279df8af58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7aadbf266e54027b23d1ab81378004a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62c146d90284922a4bf6c0f7c43e41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9178eb156d74d96a508eae1832569f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6721e9cebde748e0b7eb3c19cc924628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 500])\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "meta = processor.meta\n",
    "meta_train = meta[meta[\"train\"]==1]\n",
    "meta_test = meta[meta[\"train\"]==0]\n",
    "\n",
    "train_set = TextDataset(meta_train,\n",
    "                        processor,\n",
    "                        tokenizer)\n",
    "\n",
    "set_seed(SEED)\n",
    "train_ldr = DataLoader(train_set,\n",
    "                       16,\n",
    "                       shuffle=True,\n",
    "                       num_workers=0)\n",
    "\n",
    "for txt, lbl in train_ldr:\n",
    "    print(txt[0].size())\n",
    "    print(lbl)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c440440b",
   "metadata": {},
   "source": [
    "dataset and dataloader created\n",
    "\n",
    "next steps\n",
    "\n",
    "(i) backbone of cnn\n",
    "\n",
    "(ii) train loop\n",
    "\n",
    "(iii) quant module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62a94ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 500])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13ae01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a07867d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1360e0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Embedding??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b23ccec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141604"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tok2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "634e6873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9544"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.id2tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c57d5839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([951])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt.unique().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f94b5c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([951])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt.long().unique().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cb97c2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(42036)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt.long().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "27cfb8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141604"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tok2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bbe583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "993d413a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 torch.Size([16, 1, 499]) torch.Size([16, 1, 49])\n",
      "3 torch.Size([16, 1, 498]) torch.Size([16, 1, 49])\n",
      "4 torch.Size([16, 1, 497]) torch.Size([16, 1, 49])\n",
      "5 torch.Size([16, 1, 496]) torch.Size([16, 1, 49])\n"
     ]
    }
   ],
   "source": [
    "EMB_DIM = 10\n",
    "VOCAB_SIZE = len(tokenizer.tok2id)+1\n",
    "MAX_LEN = 500\n",
    "POOL_SIZE = 10\n",
    "\n",
    "\n",
    "inp_lin = []\n",
    "\n",
    "after_emb = nn.Embedding(VOCAB_SIZE, EMB_DIM)(txt.long())\n",
    "for i in range(2,6):    \n",
    "    after_conv = nn.Conv1d(EMB_DIM, 1, i)(after_emb.view(16,MAX_LEN,EMB_DIM).permute(0,2,1))\n",
    "    after_pool = nn.AvgPool1d(POOL_SIZE)(after_conv)\n",
    "    inp_lin.append(after_pool)    \n",
    "    print(i, after_conv.size(), after_pool.size())\n",
    "    assert after_conv.size()[-1] == MAX_LEN + 1 - i\n",
    "    assert after_pool.size()[-1] == (MAX_LEN + 1 - i) // POOL_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55a96e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_conv_size = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b9ef96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba12bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "484a6c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inp_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "144637e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 196])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(inp_lin, dim=-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "afd80cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([16, 1, 49]),\n",
       " torch.Size([16, 1, 49]),\n",
       " torch.Size([16, 1, 49]),\n",
       " torch.Size([16, 1, 49])]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[inp.size() for inp in inp_lin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751831f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffd2477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "accb59fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([16, 1, 62]),\n",
       " torch.Size([16, 1, 41]),\n",
       " torch.Size([16, 1, 31]),\n",
       " torch.Size([16, 1, 25])]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.[inp.size() for inp in inp_lin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3e2038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cda81429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((1 for i in range(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9786d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a2a854e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustConv_(nn.Conv1d):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size):\n",
    "        super(CustConv_, self).__init__(in_channels,\n",
    "                                        out_channels,\n",
    "                                        kernel_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc084bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8f528403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 num_classes,\n",
    "                 max_len,\n",
    "                 vocab_size,\n",
    "                 ksize_min,\n",
    "                 ksize_max,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 pool_size,\n",
    "                 custom_layers={}):\n",
    "        super(CNN_Text, self).__init__()\n",
    "        assert ksize_min > 1 and \\\n",
    "                ksize_max > ksize_min and \\\n",
    "                ksize_max < max_len, \\\n",
    "                \"kernel size must exceed 1 and be less than maximum length\"\n",
    "        assert isinstance(custom_layers, dict), \"custom layers must be a dict\"\n",
    "        self.max_len = max_len\n",
    "        self.ksize_min = ksize_min\n",
    "        self.ksize_max = ksize_max\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.pool_size = pool_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.in_linear = sum(((self.max_len + 1 - ksize) // self.pool_size \n",
    "                              for ksize in range(self.ksize_min, self.ksize_max+1)))\n",
    "        self.out_linear = 1 if num_classes == 2 else num_classes\n",
    "        self.funcs = {\n",
    "            \"avgpool\": nn.AvgPool1d,\n",
    "            \"emb\": nn.Embedding,\n",
    "            \"conv\": nn.Conv1d,\n",
    "            \"lin\": nn.Linear,\n",
    "            \"act\": nn.Sigmoid\n",
    "        }\n",
    "        \n",
    "        if custom_layers:\n",
    "            for layer_name, layer in custom_layers.items():\n",
    "                if self.funcs.get(layer_name):\n",
    "                    self.funcs[layer_name] = layer\n",
    "        \n",
    "        self.layers = {\n",
    "            \"avgpool\": self.funcs[\"avgpool\"](self.pool_size),\n",
    "            \"emb\": self.funcs[\"emb\"](self.vocab_size+1,\n",
    "                                self.in_channels),\n",
    "            \"convs\": [self.funcs[\"conv\"](self.in_channels,\n",
    "                                self.out_channels,\n",
    "                                ksize) for ksize in \\\n",
    "                                range(self.ksize_min, self.ksize_max+1)],\n",
    "            \"lin\": self.funcs[\"lin\"](self.in_linear, \n",
    "                             self.out_linear),\n",
    "            \"act\": self.funcs[\"act\"]()\n",
    "        }\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # TO DO: calculations\n",
    "        return x\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0684a09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cnn = CNN_Text(num_classes=2,\n",
    "         max_len=MAX_LEN,\n",
    "         vocab_size=VOCAB_SIZE,\n",
    "         ksize_min=2,\n",
    "         ksize_max=6,\n",
    "         in_channels=10,\n",
    "         out_channels=1,\n",
    "         pool_size=POOL_SIZE,\n",
    "         custom_layers={\"conv\": CustConv_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2ab72790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avgpool': AvgPool1d(kernel_size=(10,), stride=(10,), padding=(0,)),\n",
       " 'emb': Embedding(141606, 10),\n",
       " 'convs': [CustConv_(10, 1, kernel_size=(2,), stride=(1,)),\n",
       "  CustConv_(10, 1, kernel_size=(3,), stride=(1,)),\n",
       "  CustConv_(10, 1, kernel_size=(4,), stride=(1,)),\n",
       "  CustConv_(10, 1, kernel_size=(5,), stride=(1,)),\n",
       "  CustConv_(10, 1, kernel_size=(6,), stride=(1,))],\n",
       " 'lin': Linear(in_features=245, out_features=1, bias=True),\n",
       " 'act': Sigmoid()}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cnn.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16918153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0d3754be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(141606, 10)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cnn.layers[\"emb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31509a53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
