{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a83e519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from gpt2_classifier import (\n",
    "    init_gpt2,\n",
    "    freeze_layers,\n",
    "    GPT2ForSequenceClassification\n",
    ")\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AddedToken, GPT2Config, GPT2Tokenizer #, GPT2ForSequenceClassification, GPT2Model\n",
    "from tqdm.autonotebook import tqdm\n",
    "from utils import (\n",
    "    calc_accuracy,\n",
    "    custom_data_gen,\n",
    "    init_data,\n",
    "    init_quant_params,\n",
    "    measure_inference_time,\n",
    "    rnd,\n",
    "    run_batch\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f5f2dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-4\n",
    "LR_DECAY = 0.8\n",
    "MIN_LR = 5e-6\n",
    "N_EPOCHS = 1\n",
    "PLATEAU = 3\n",
    "BATCH_SIZE = 256\n",
    "MAX_LEN = 100\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e88e85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.add_special_tokens({\n",
    "    \"pad_token\": AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db20120",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"metrics_quant.json\", \"r\") as f:\n",
    "    dict_acc = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b362039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fp16': 0.9177964154411765,\n",
       " 'dynamic16': 0.9177676930147058,\n",
       " 'dynamic8': 0.9102424172794118,\n",
       " 'dynamic4': 0.0744485294117647,\n",
       " 'static16': 0.9177964154411765,\n",
       " 'static8': 0.9102424172794118,\n",
       " 'static4': 0.0732421875}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b14880dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_acc = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b0f1ee",
   "metadata": {},
   "source": [
    "__Full precision accuracy__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "213c135e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683977dbc71f48a6b1e57211d66f92c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9177964154411765\n"
     ]
    }
   ],
   "source": [
    "quantization = {\"type\": \"fp\",\n",
    "                \"n_bits\": 16}\n",
    "data_infer = init_data(\"infer\")\n",
    "\n",
    "model_fp = init_gpt2(tokenizer,\n",
    "                  DEVICE,\n",
    "                  quantization=quantization)\n",
    "checkpoint = \"gpt2_best_epoch_1_loss_1.80571.pt\"\n",
    "model_fp.load_state_dict(torch.load(checkpoint))\n",
    "\n",
    "acc_fp = calc_accuracy(model_fp,\n",
    "                       data_infer,\n",
    "                       tokenizer)\n",
    "print(acc_fp)\n",
    "\n",
    "dict_acc[quantization[\"type\"]+str(quantization[\"n_bits\"])] = acc_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1397f6",
   "metadata": {},
   "source": [
    "__16 bits dynamic quant. accuracy__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd5666bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a96398d9fd041b8afa4315ef29a0812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9177676930147058\n"
     ]
    }
   ],
   "source": [
    "quantization = {\"type\": \"dynamic\",\n",
    "                \"n_bits\": 16}\n",
    "data_infer = init_data(\"infer\")\n",
    "\n",
    "\n",
    "model_dyn_16 = init_gpt2(tokenizer,\n",
    "                  DEVICE,\n",
    "                  quantization=quantization)\n",
    "checkpoint = \"gpt2_best_epoch_1_loss_1.80571.pt\"\n",
    "model_dyn_16.load_state_dict(torch.load(checkpoint))\n",
    "\n",
    "acc_dyn_16 = calc_accuracy(model_dyn_16,\n",
    "                           data_infer,\n",
    "                           tokenizer)\n",
    "print(acc_dyn_16)\n",
    "\n",
    "dict_acc[quantization[\"type\"]+str(quantization[\"n_bits\"])] = acc_dyn_16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e8ccac",
   "metadata": {},
   "source": [
    "__8 bits dynamic quant. accuracy__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99f0e532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10fc1f6eb07349eebb059418571e4cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9102424172794118\n"
     ]
    }
   ],
   "source": [
    "quantization = {\"type\": \"dynamic\",\n",
    "                \"n_bits\": 8}\n",
    "data_infer = init_data(\"infer\")\n",
    "\n",
    "\n",
    "model_dyn_8 = init_gpt2(tokenizer,\n",
    "                  DEVICE,\n",
    "                  quantization=quantization)\n",
    "checkpoint = \"gpt2_best_epoch_1_loss_1.80571.pt\"\n",
    "model_dyn_8.load_state_dict(torch.load(checkpoint))\n",
    "\n",
    "acc_dyn_8 = calc_accuracy(model_dyn_8,\n",
    "                           data_infer,\n",
    "                           tokenizer)\n",
    "print(acc_dyn_8)\n",
    "\n",
    "dict_acc[quantization[\"type\"]+str(quantization[\"n_bits\"])] = acc_dyn_8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ab9d8f",
   "metadata": {},
   "source": [
    "__4 bits dynamic quant accuracy__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75129686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0271becd8d5443b5906575c89ebb3024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0744485294117647\n"
     ]
    }
   ],
   "source": [
    "quantization = {\"type\": \"dynamic\",\n",
    "                \"n_bits\": 4}\n",
    "data_infer = init_data(\"infer\")\n",
    "\n",
    "\n",
    "model_dyn_4 = init_gpt2(tokenizer,\n",
    "                        DEVICE,\n",
    "                        quantization=quantization)\n",
    "checkpoint = \"gpt2_best_epoch_1_loss_1.80571.pt\"\n",
    "model_dyn_4.load_state_dict(torch.load(checkpoint))\n",
    "\n",
    "acc_dyn_4 = calc_accuracy(model_dyn_4,\n",
    "                          data_infer,\n",
    "                          tokenizer)\n",
    "print(acc_dyn_4)\n",
    "\n",
    "dict_acc[quantization[\"type\"]+str(quantization[\"n_bits\"])] = acc_dyn_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385f0c1b",
   "metadata": {},
   "source": [
    "__16 bits static quant accuracy__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06c56511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c790f96f86384771bc63cf8499df5d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e118752002049d98a9d8e8a0a3d622c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9178251378676471\n"
     ]
    }
   ],
   "source": [
    "quantization = {\"type\": \"static\",\n",
    "                \"n_bits\": 16}\n",
    "\n",
    "data_quant = init_data(\"quant\")\n",
    "data_infer = init_data(\"infer\")\n",
    "\n",
    "\n",
    "model_stat_16 = init_gpt2(tokenizer,\n",
    "                          DEVICE,\n",
    "                          quantization=quantization)\n",
    "checkpoint = \"gpt2_best_epoch_1_loss_1.80571.pt\"\n",
    "model_stat_16.load_state_dict(torch.load(checkpoint))\n",
    "model_stat_16 = init_quant_params(model_stat_16,\n",
    "                                  data_quant,\n",
    "                                  tokenizer)\n",
    "\n",
    "acc_stat_16 = calc_accuracy(model_stat_16,\n",
    "                            data_infer,\n",
    "                            tokenizer)\n",
    "print(acc_stat_16)\n",
    "\n",
    "dict_acc[quantization[\"type\"]+str(quantization[\"n_bits\"])] = acc_stat_16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55fef30",
   "metadata": {},
   "source": [
    "__8 bits static quant accuracy__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e244b300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3136b7d03fe540d8a0560b9a392cf8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8dc3b63601640db9ec95d572fd9e02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9128274356617647\n"
     ]
    }
   ],
   "source": [
    "quantization = {\"type\": \"static\",\n",
    "                \"n_bits\": 8}\n",
    "\n",
    "data_quant = init_data(\"quant\")\n",
    "data_infer = init_data(\"infer\")\n",
    "\n",
    "\n",
    "model_stat_8 = init_gpt2(tokenizer,\n",
    "                         DEVICE,\n",
    "                         quantization=quantization)\n",
    "checkpoint = \"gpt2_best_epoch_1_loss_1.80571.pt\"\n",
    "model_stat_8.load_state_dict(torch.load(checkpoint))\n",
    "model_stat_8 = init_quant_params(model_stat_8,\n",
    "                                  data_quant,\n",
    "                                  tokenizer)\n",
    "\n",
    "acc_stat_8 = calc_accuracy(model_stat_8,\n",
    "                           data_infer,\n",
    "                           tokenizer)\n",
    "print(acc_stat_8)\n",
    "\n",
    "dict_acc[quantization[\"type\"]+str(quantization[\"n_bits\"])] = acc_stat_8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58063cbc",
   "metadata": {},
   "source": [
    "__4 bits static quant accuracy__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed952348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1162b63547494c0f909121c61a5618d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c931af0f224efe9e60790dfc287b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29719094669117646\n"
     ]
    }
   ],
   "source": [
    "quantization = {\"type\": \"static\",\n",
    "                \"n_bits\": 4}\n",
    "\n",
    "data_quant = init_data(\"quant\")\n",
    "data_infer = init_data(\"infer\")\n",
    "\n",
    "\n",
    "model_stat_4 = init_gpt2(tokenizer,\n",
    "                         DEVICE,\n",
    "                         quantization=quantization)\n",
    "checkpoint = \"gpt2_best_epoch_1_loss_1.80571.pt\"\n",
    "model_stat_4.load_state_dict(torch.load(checkpoint))\n",
    "model_stat_4 = init_quant_params(model_stat_4,\n",
    "                                 data_quant,\n",
    "                                 tokenizer)\n",
    "\n",
    "acc_stat_4 = calc_accuracy(model_stat_4,\n",
    "                           data_infer,\n",
    "                           tokenizer)\n",
    "print(acc_stat_4)\n",
    "\n",
    "dict_acc[quantization[\"type\"]+str(quantization[\"n_bits\"])] = acc_stat_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1679bbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stat_16.transformer.h[10].attn.c_attn.static_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6108fee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff3601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e08a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "339b8fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"metrics_quant.json\", \"w\") as f:\n",
    "    json.dump(dict_acc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1b031a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
